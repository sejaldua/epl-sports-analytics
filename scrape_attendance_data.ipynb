{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/Pillow-9.5.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/Pillow-9.5.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: beautifulsoup4 in /opt/homebrew/lib/python3.11/site-packages (4.12.0)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.11/site-packages (4.65.0)\n",
      "Requirement already satisfied: lxml in /opt/homebrew/lib/python3.11/site-packages (4.9.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/homebrew/lib/python3.11/site-packages (from beautifulsoup4) (2.4)\n",
      "\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/Pillow-9.5.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/Pillow-9.5.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/Pillow-9.5.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/Pillow-9.5.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install beautifulsoup4 tqdm lxml\n",
    "\n",
    "# alternative to selenium\n",
    "# !python3 -m pip install playwright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:55<00:00,  5.52s/it]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "SEASONS = list(range(2012,2022))\n",
    "\n",
    "def scrape_season(season):\n",
    "    if season == 2022:\n",
    "        url = \"https://fbref.com/en/comps/9/schedule/Premier-League-Scores-and-Fixtures\"\n",
    "    else:\n",
    "        url = f\"https://fbref.com/en/comps/9/{season}-{season+1}/schedule/{season}-{season+1}-Premier-League-Scores-and-Fixtures\"\n",
    "    hdr = { 'User-Agent' : 'Mozilla/5.0 (Windows NT 6.1; Win64; x64)' }\n",
    "    req = urllib.request.Request(url, headers=hdr)\n",
    "    html = urllib.request.urlopen(req)\n",
    "\n",
    "    # access relevant parts of the page via beautiful soup\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    table = soup.find('table')\n",
    "    header_row = table.find('thead')\n",
    "    body = table.find('tbody')\n",
    "\n",
    "    # use getText()to extract the headers into a list\n",
    "    headers = [*[th.getText() for th in header_row.findAll('th')], 'Season']\n",
    "\n",
    "    # iterate through table row by row and scrape player data\n",
    "    data = [[i, *[td.getText() for td in row.findAll('td')], int(season)] for i, row in enumerate(body.findAll('tr'))]\n",
    "\n",
    "    # NOTE: sports reference does not allow more than 20 requests per minute\n",
    "    # so we must sleep for 5 seconds\n",
    "    time.sleep(5)\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    df = df[[col for col in df.columns if col != 'xG']]\n",
    "    return df\n",
    "\n",
    "# iteratively scrape each season worth of player stats and concatenate data into 1 dataframe\n",
    "df = pd.DataFrame()\n",
    "for season in tqdm(SEASONS):\n",
    "    df = pd.concat([df, scrape_season(season)], ignore_index=True, axis=0)\n",
    "\n",
    "df = df[df['Attendance'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "df.to_csv('epl-attendance.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dae7da88b31f03f134a269414e735646eb28aef172fdec5380d41c390c8e66ac"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('3.9.13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
